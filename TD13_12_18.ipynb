{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Tutorial in python using the iris dataset\n",
    "## DISCRIMINANT ANALYSIS IN THE GAUSSIAN FRAMEWORK\n",
    "### Problem Statement and Hypothesis\n",
    "In the very first place, our goal is: from the following dataset, $$ \\left\\{ (x_i,y_i \\right\\}_{i=1}^n ~where ~ (x_i,y_i)\\in \\mathbb{R}^p \\times \\{1,\\ldots,k\\} ~with~ k\\in \\mathbb{N} \\backslash \\{0,1\\} ~and~\\{1,\\ldots,k\\} ~not~ ordered$$  predict the class of an individual $X$ using the Bayes classifier\n",
    "\\begin{eqnarray}\n",
    "        g^*(x) &=& \\arg\\max_{k\\in\\{1,\\ldots,k\\}} \\frac{\\mathbb{P}(Y=k)f_{X|Y=k}(x)}{\\displaystyle{\\sum_{h=1}^K \\mathbb{P}(Y=h)f_{X|Y=h}(x)}} \\\\ &=&\\arg\\max_{k\\in\\{1,\\ldots,k\\}} \\mathbb{P}(Y=k)f_{X|Y=k}(x)\n",
    "\\end{eqnarray}\n",
    "\n",
    "$$where~f_{X|Y=k}(x):= \\mathscr{N}(x; \\mu_k, \\Lambda_k) = \\frac{1}{(2\\pi)^{\\frac{p}{2}} \\left| \\Lambda_k \\right|^{\\frac{1}{2}}} \\exp\\left[ -\\frac{1}{2} ~ ^t (x-\\mu_k)\\Lambda_k^{-1}(x-\\mu_k) \\right]$$\n",
    "\n",
    "But, we realise that this classifier, depends on variables which we don't know $$\\theta = \\left( (\\omega_k)_{k=1}^K,  (\\mu_k)_{k=1}^K,  (\\Lambda_k)_{k=1}^K\\right)$$ after getting the boundary equation between two classes $(k$ and $k')$ for $k>2$, given as:\n",
    "$$ \\frac{1}{2} \\ln \\frac{|\\Lambda_{k'}|}{|\\Lambda_k|} + \\ln\\frac{\\omega_k}{\\omega_{k'}} + \\frac{1}{2} \\left[ ^t (x-\\mu_{k'})\\Lambda_{k'}^{-1}(x-\\mu_{k'}) - ^t (x-\\mu_k)\\Lambda_k^{-1}(x-\\mu_k) \\right] = 0$$ Where $\\omega_k = \\mathbb{P}(Y=k)$\n",
    "\n",
    "#### Estimating $\\theta$\n",
    "$\\mathbb{P}(Y_i = k) = \\omega_k$$~;~~$   $f_{X|Y=k}(x):= \\mathscr{N}(x; \\mu_k, \\Lambda_k)$, we record the $Y_i$'s in $Z_i = \\left( Z_{i,k} \\right)_{k=1}^K \\in \\left\\{ 0,1 \\right\\}$ where $Z_{i,k} = \\mathbb{P}(Z_{i,k}=1) = \\omega_k$. The dataset now becomes \n",
    "$$\\mathscr{A}_n = \\left\\{ (x_i,y_i) \\right\\}_{i=1}^n = \\left\\{ \\left( x_i; (z_{i,k})_{k=1}^K \\right) \\right\\}  $$\n",
    "\n",
    "Our goal now boils down to estimating these variables since we do not know them and to do this, we estimate them by calculating the maximum likelihood estimator $$\\widehat{\\theta} = \\left( (\\widehat{\\omega}_k)_{k=1}^K,  (\\widehat{\\mu}_k)_{k=1}^K,  (\\widehat{\\Lambda}_k)_{k=1}^K\\right) \\in \\arg\\max_{\\theta} L\\left( \\theta,(x,y) \\right)$$ where \n",
    "$$ L\\left( \\theta,(x,y) \\right) = \\sum_{i=1}^n \\sum_{k=1}^K z_{i,k} \\left[ \\ln\\left( \\frac{1}{(2\\pi)^{\\frac{p}{2}} \\left| \\Lambda_k \\right|^{\\frac{1}{2}}} \\right) - \\frac{1}{2} ~ ^t (x_i-\\mu_k)\\Lambda_k^{-1}(x_i-\\mu_k) + \\ln{\\omega_k}\\right] + \\lambda \\left( \\sum_{k=1}^K \\omega_k - 1\\right)$$\n",
    "$$and,~~ \\left\\{ \\begin{array}{l}\n",
    "    n_k = \\displaystyle{\\sum_{i=1}^nz_{i,k}} \\\\\n",
    "    \\widehat{\\omega} = \\displaystyle{\\frac{n_k}{n}} \\\\\n",
    "    \\widehat{\\mu}_k = \\displaystyle{\\frac{1}{n_k} \\sum_{i=1}^nz_{i,k}x_i} \\\\\n",
    "    \\displaystyle{\\widehat{\\Lambda}_k =  \\frac{1}{n_k} \\sum_{i=1}^nz_{i,k} (x_i-\\widehat{\\mu}_k) ~^t (x_i-\\widehat{\\mu}_k)}\n",
    " \\end{array} \\right.\n",
    " $$\n",
    " After all the calculations done on L using Langrangien optimisation based on variables, we obtain the expressions for $n_k, \\widehat{\\omega},\\widehat{\\mu}_k and \\widehat{\\Lambda}_k $ as seen above. We also come out with the following discriminant function for the class $k$\n",
    " $$\\widehat{\\delta}_k(x) = -\\frac{1}{2} \\ln \\left|\\widehat{\\Lambda}_k\\right| + \\ln \\widehat{\\omega}_k - \\frac{1}{2} ~ ^t (x-\\widehat{\\mu}_k)\\Lambda_k^{-1}(x-\\widehat{\\mu}_k)$$\n",
    "\n",
    " Finally, we have estimated $\\theta$ on which our predictor depends, we therefore can determine our classifier using \n",
    "$$\\widehat{g}(x) = \\arg\\max_k\\widehat{\\delta}_k(x) $$\n",
    " \n",
    " In second place we are going to use $\\Lambda$ calculated as follows  \n",
    " $$\\widehat{\\Lambda} =  \\frac{1}{n} \\sum_{i=1}^n \\sum_{k=1}^Kz_{i,k} (x_i-\\widehat{\\mu}_k) ~^t (x_i-\\widehat{\\mu}_k)$$\n",
    " and it's corresponding $\\widehat{\\delta}_k(x)$ as follows\n",
    " $$\\widehat{\\delta}_k(x) = -\\frac{1}{2} \\ln \\left|\\widehat{\\Lambda}\\right| + \\ln \\widehat{\\omega}_k - \\frac{1}{2} ~ ^t (x-\\widehat{\\mu}_k)\\Lambda^{-1}(x-\\widehat{\\mu}_k)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing of various libraries\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_Y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "Z = []\n",
    "for i in range(len(iris_Y)):\n",
    "    Z.append([None]*(k+1))\n",
    "    for j in range(k+1):\n",
    "        if(iris_Y[i] == j):\n",
    "            Z[i][j] = 1\n",
    "        else:\n",
    "            Z[i][j] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of $\\theta$ using a class MyEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimation of \\theta\n",
    "class MyEstimator(object):\n",
    "    def __init__(self,Z,X,n,k):\n",
    "        self._X = X.copy()\n",
    "        self._Z = Z.copy()\n",
    "        self._n = n\n",
    "        self._k = k\n",
    "        \n",
    "    # maximum likelihood estimator of nk    \n",
    "    def Nk(self):\n",
    "        nk = []\n",
    "        for j in range (k+1):\n",
    "            nk.append(0) \n",
    "            for i in range(self._n):\n",
    "                nk[j] += self._Z[i][j]\n",
    "        return nk\n",
    "    \n",
    "     # maximum likelihood estimator of wk \n",
    "    def Wk(self):\n",
    "        self._nk = self.Nk()\n",
    "        wk = []\n",
    "        for j in range(len(self._nk)):\n",
    "            wk.append(0)\n",
    "            wk[j] = self._nk[j]/self._n\n",
    "        return wk\n",
    "    \n",
    "     # maximum likelihood estimator of Muk \n",
    "    def Muk(self):\n",
    "        Muk = []\n",
    "        self._nk = self.Nk()\n",
    "        for j in range (k+1):\n",
    "            #Muk.append([0,0,0,0])\n",
    "            Muk.append([0]*len(self._X[0])) \n",
    "            for i in range(self._n):\n",
    "                Muk[j] += (1/self._nk[j])*(self._Z[i][j]*np.matrix(self._X[i]))\n",
    "        return Muk\n",
    "    \n",
    "    def transP(self,a):\n",
    "        b = np.array([a])\n",
    "        return b.T\n",
    "    \n",
    "    #maximum likelihood estimator of Lamdak\n",
    "    def Lamdak(self):\n",
    "        Lamdak = []\n",
    "        self._Muk = self.Muk()\n",
    "        for j in range (k+1):\n",
    "            Lamdak.append([0]*len(self._X[0])) \n",
    "            for i in range(self._n):\n",
    "                D = self._X[i] - self._Muk[j]\n",
    "                # TODO Ask teacher about I have a problem with the method below\n",
    "                Lamdak[j] += (1/self._nk[j])*(self._Z[i][j]*np.matrix(D).T.dot(np.matrix(D)))\n",
    "        return Lamdak\n",
    "    \n",
    "    #maximum likelihood estimator of Lamda\n",
    "    def Lamda(self):\n",
    "        Lamda = []\n",
    "        prod = []\n",
    "        Lamda.append([0]*len(self._X[0]))\n",
    "        self._Muk = self.Muk()\n",
    "        for i in range(self._n):\n",
    "            for j in range (k+1):\n",
    "                prod.append([0]*len(self._X[0]))\n",
    "                D = self._X[i] - self._Muk[j]\n",
    "                prod[i] += (self._Z[i][j]*np.matrix(D).T.dot(np.matrix(D)))\n",
    "            Lamda += (1/self._n)*prod[i]\n",
    "        return Lamda\n",
    "    \n",
    "    #Discriminant function of every class k for a given X using Lamdak\n",
    "    def sigmaCap(self,X):\n",
    "        sigmacap = []\n",
    "        self._lamdak = self.Lamdak()\n",
    "        self._wk = self.Wk()\n",
    "        for j in range (k+1):\n",
    "            sigmacap.append(0) \n",
    "            D = X - self._Muk[j]\n",
    "            # TODO Ask teacher about I have a problem with the method below\n",
    "            sigmacap[j] = -0.5*np.log(np.linalg.det(self._lamdak[j])) + np.log(self._wk[j]) - 0.5*np.matrix(D).dot(np.linalg.inv(self._lamdak[k])).dot(np.matrix(D).T) \n",
    "        return sigmacap\n",
    "    \n",
    "     #Discriminant function of every class k for a given X using Lamda \n",
    "    def sigmaCapLamda(self,X):\n",
    "        sigmacapLamda = []\n",
    "        self._lamda = self.Lamda()\n",
    "        self._wk = self.Wk()\n",
    "        for j in range (k+1):\n",
    "            sigmacapLamda.append(0) \n",
    "            D = X - self._Muk[j]\n",
    "            sigmacapLamda[j] = -0.5*np.log(np.linalg.det(self._lamda)) + np.log(self._wk[j]) - 0.5*np.matrix(D).dot(np.linalg.inv(self._lamda)).dot(np.matrix(D).T) \n",
    "        return sigmacapLamda\n",
    "    \n",
    "     #Determining the class of a given X \n",
    "        '''\n",
    "            This method is used to predict using Lamdak\n",
    "        '''\n",
    "    def gcap(self,X):\n",
    "        gcap = self.sigmaCap(X)\n",
    "        index = gcap.index(np.max(gcap))\n",
    "        return index\n",
    "    \n",
    "     #Determining the class of a given X using Lamda\n",
    "        '''\n",
    "            This method is used to predict using Lamda\n",
    "        '''\n",
    "    def gcapLamda(self,X):\n",
    "        gcap = self.sigmaCapLamda(X)\n",
    "        index = gcap.index(np.max(gcap))\n",
    "        return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Using $\\widehat{\\Lambda}_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = MyEstimator(Z,iris_X,len(iris_Y),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimating $n_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 50, 50]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.Nk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimating $\\widehat{\\omega}_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.Wk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimating $\\widehat{\\mu}_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[matrix([[5.006, 3.418, 1.464, 0.244]]),\n",
       " matrix([[5.936, 2.77 , 4.26 , 1.326]]),\n",
       " matrix([[6.588, 2.974, 5.552, 2.026]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.Muk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimating $\\widehat{\\Lambda}_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[matrix([[0.121764, 0.098292, 0.015816, 0.010336],\n",
       "         [0.098292, 0.142276, 0.011448, 0.011208],\n",
       "         [0.015816, 0.011448, 0.029504, 0.005584],\n",
       "         [0.010336, 0.011208, 0.005584, 0.011264]]),\n",
       " matrix([[0.261104, 0.08348 , 0.17924 , 0.054664],\n",
       "         [0.08348 , 0.0965  , 0.081   , 0.04038 ],\n",
       "         [0.17924 , 0.081   , 0.2164  , 0.07164 ],\n",
       "         [0.054664, 0.04038 , 0.07164 , 0.038324]]),\n",
       " matrix([[0.396256, 0.091888, 0.297224, 0.048112],\n",
       "         [0.091888, 0.101924, 0.069952, 0.046676],\n",
       "         [0.297224, 0.069952, 0.298496, 0.047848],\n",
       "         [0.048112, 0.046676, 0.047848, 0.073924]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.Lamdak()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementing class on iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For [5.1 3.5 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.9 3.  1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.7 3.2 1.3 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.6 3.1 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.6 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.4 3.9 1.7 0.4], 0 (setosa) predicted as expected.\n",
      "For [4.6 3.4 1.4 0.3], 0 (setosa) predicted as expected.\n",
      "For [5.  3.4 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.4 2.9 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.9 3.1 1.5 0.1], 0 (setosa) predicted as expected.\n",
      "For [5.4 3.7 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.8 3.4 1.6 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.8 3.  1.4 0.1], 0 (setosa) predicted as expected.\n",
      "For [4.3 3.  1.1 0.1], 0 (setosa) predicted as expected.\n",
      "For [5.8 4.  1.2 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.7 4.4 1.5 0.4], 0 (setosa) predicted as expected.\n",
      "For [5.4 3.9 1.3 0.4], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.5 1.4 0.3], 0 (setosa) predicted as expected.\n",
      "For [5.7 3.8 1.7 0.3], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.8 1.5 0.3], 0 (setosa) predicted as expected.\n",
      "For [5.4 3.4 1.7 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.7 1.5 0.4], 0 (setosa) predicted as expected.\n",
      "For [4.6 3.6 1.  0.2], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.3 1.7 0.5], 0 (setosa) predicted as expected.\n",
      "For [4.8 3.4 1.9 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.  1.6 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.4 1.6 0.4], 0 (setosa) predicted as expected.\n",
      "For [5.2 3.5 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.2 3.4 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.7 3.2 1.6 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.8 3.1 1.6 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.4 3.4 1.5 0.4], 0 (setosa) predicted as expected.\n",
      "For [5.2 4.1 1.5 0.1], 0 (setosa) predicted as expected.\n",
      "For [5.5 4.2 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.9 3.1 1.5 0.1], 0 (setosa) predicted as expected.\n",
      "For [5.  3.2 1.2 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.5 3.5 1.3 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.9 3.1 1.5 0.1], 0 (setosa) predicted as expected.\n",
      "For [4.4 3.  1.3 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.4 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.5 1.3 0.3], 0 (setosa) predicted as expected.\n",
      "For [4.5 2.3 1.3 0.3], 0 (setosa) predicted as expected.\n",
      "For [4.4 3.2 1.3 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.5 1.6 0.6], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.8 1.9 0.4], 0 (setosa) predicted as expected.\n",
      "For [4.8 3.  1.4 0.3], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.8 1.6 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.6 3.2 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.3 3.7 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.3 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [7.  3.2 4.7 1.4], 1 (versicolor) predicted as expected.\n",
      "For [6.4 3.2 4.5 1.5], 1 (versicolor) predicted as expected.\n",
      "For [6.9 3.1 4.9 1.5], 1 (versicolor) predicted as expected.\n",
      "For [5.5 2.3 4.  1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.5 2.8 4.6 1.5], 1 (versicolor) predicted as expected.\n",
      "For [5.7 2.8 4.5 1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.3 3.3 4.7 1.6], 1 (versicolor) predicted as expected.\n",
      "For [4.9 2.4 3.3 1. ], 1 (versicolor) predicted as expected.\n",
      "For [6.6 2.9 4.6 1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.2 2.7 3.9 1.4], 1 (versicolor) predicted as expected.\n",
      "For [5.  2.  3.5 1. ], 1 (versicolor) predicted as expected.\n",
      "For [5.9 3.  4.2 1.5], 1 (versicolor) predicted as expected.\n",
      "For [6.  2.2 4.  1. ], 1 (versicolor) predicted as expected.\n",
      "For [6.1 2.9 4.7 1.4], 1 (versicolor) predicted as expected.\n",
      "For [5.6 2.9 3.6 1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.7 3.1 4.4 1.4], 1 (versicolor) predicted as expected.\n",
      "For [5.6 3.  4.5 1.5], 1 (versicolor) predicted as expected.\n",
      "For [5.8 2.7 4.1 1. ], 1 (versicolor) predicted as expected.\n",
      "For [6.2 2.2 4.5 1.5], 1 (versicolor) predicted as expected.\n",
      "For [5.6 2.5 3.9 1.1], 1 (versicolor) predicted as expected.\n",
      "For [5.9 3.2 4.8 1.8], 2 (virginica) predicted instead of 1 (versicolor).\n",
      "For [6.1 2.8 4.  1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.3 2.5 4.9 1.5], 1 (versicolor) predicted as expected.\n",
      "For [6.1 2.8 4.7 1.2], 1 (versicolor) predicted as expected.\n",
      "For [6.4 2.9 4.3 1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.6 3.  4.4 1.4], 1 (versicolor) predicted as expected.\n",
      "For [6.8 2.8 4.8 1.4], 1 (versicolor) predicted as expected.\n",
      "For [6.7 3.  5.  1.7], 1 (versicolor) predicted as expected.\n",
      "For [6.  2.9 4.5 1.5], 1 (versicolor) predicted as expected.\n",
      "For [5.7 2.6 3.5 1. ], 1 (versicolor) predicted as expected.\n",
      "For [5.5 2.4 3.8 1.1], 1 (versicolor) predicted as expected.\n",
      "For [5.5 2.4 3.7 1. ], 1 (versicolor) predicted as expected.\n",
      "For [5.8 2.7 3.9 1.2], 1 (versicolor) predicted as expected.\n",
      "For [6.  2.7 5.1 1.6], 2 (virginica) predicted instead of 1 (versicolor).\n",
      "For [5.4 3.  4.5 1.5], 1 (versicolor) predicted as expected.\n",
      "For [6.  3.4 4.5 1.6], 1 (versicolor) predicted as expected.\n",
      "For [6.7 3.1 4.7 1.5], 1 (versicolor) predicted as expected.\n",
      "For [6.3 2.3 4.4 1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.6 3.  4.1 1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.5 2.5 4.  1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.5 2.6 4.4 1.2], 1 (versicolor) predicted as expected.\n",
      "For [6.1 3.  4.6 1.4], 1 (versicolor) predicted as expected.\n",
      "For [5.8 2.6 4.  1.2], 1 (versicolor) predicted as expected.\n",
      "For [5.  2.3 3.3 1. ], 1 (versicolor) predicted as expected.\n",
      "For [5.6 2.7 4.2 1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.7 3.  4.2 1.2], 1 (versicolor) predicted as expected.\n",
      "For [5.7 2.9 4.2 1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.2 2.9 4.3 1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.1 2.5 3.  1.1], 1 (versicolor) predicted as expected.\n",
      "For [5.7 2.8 4.1 1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.3 3.3 6.  2.5], 2 (virginica) predicted as expected.\n",
      "For [5.8 2.7 5.1 1.9], 2 (virginica) predicted as expected.\n",
      "For [7.1 3.  5.9 2.1], 2 (virginica) predicted as expected.\n",
      "For [6.3 2.9 5.6 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.5 3.  5.8 2.2], 2 (virginica) predicted as expected.\n",
      "For [7.6 3.  6.6 2.1], 2 (virginica) predicted as expected.\n",
      "For [4.9 2.5 4.5 1.7], 2 (virginica) predicted as expected.\n",
      "For [7.3 2.9 6.3 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.7 2.5 5.8 1.8], 2 (virginica) predicted as expected.\n",
      "For [7.2 3.6 6.1 2.5], 2 (virginica) predicted as expected.\n",
      "For [6.5 3.2 5.1 2. ], 2 (virginica) predicted as expected.\n",
      "For [6.4 2.7 5.3 1.9], 2 (virginica) predicted as expected.\n",
      "For [6.8 3.  5.5 2.1], 2 (virginica) predicted as expected.\n",
      "For [5.7 2.5 5.  2. ], 2 (virginica) predicted as expected.\n",
      "For [5.8 2.8 5.1 2.4], 2 (virginica) predicted as expected.\n",
      "For [6.4 3.2 5.3 2.3], 2 (virginica) predicted as expected.\n",
      "For [6.5 3.  5.5 1.8], 2 (virginica) predicted as expected.\n",
      "For [7.7 3.8 6.7 2.2], 2 (virginica) predicted as expected.\n",
      "For [7.7 2.6 6.9 2.3], 2 (virginica) predicted as expected.\n",
      "For [6.  2.2 5.  1.5], 2 (virginica) predicted as expected.\n",
      "For [6.9 3.2 5.7 2.3], 2 (virginica) predicted as expected.\n",
      "For [5.6 2.8 4.9 2. ], 2 (virginica) predicted as expected.\n",
      "For [7.7 2.8 6.7 2. ], 2 (virginica) predicted as expected.\n",
      "For [6.3 2.7 4.9 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.7 3.3 5.7 2.1], 2 (virginica) predicted as expected.\n",
      "For [7.2 3.2 6.  1.8], 2 (virginica) predicted as expected.\n",
      "For [6.2 2.8 4.8 1.8], 1 (versicolor) predicted instead of 2 (virginica).\n",
      "For [6.1 3.  4.9 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.4 2.8 5.6 2.1], 2 (virginica) predicted as expected.\n",
      "For [7.2 3.  5.8 1.6], 2 (virginica) predicted as expected.\n",
      "For [7.4 2.8 6.1 1.9], 2 (virginica) predicted as expected.\n",
      "For [7.9 3.8 6.4 2. ], 2 (virginica) predicted as expected.\n",
      "For [6.4 2.8 5.6 2.2], 2 (virginica) predicted as expected.\n",
      "For [6.3 2.8 5.1 1.5], 1 (versicolor) predicted instead of 2 (virginica).\n",
      "For [6.1 2.6 5.6 1.4], 2 (virginica) predicted as expected.\n",
      "For [7.7 3.  6.1 2.3], 2 (virginica) predicted as expected.\n",
      "For [6.3 3.4 5.6 2.4], 2 (virginica) predicted as expected.\n",
      "For [6.4 3.1 5.5 1.8], 2 (virginica) predicted as expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For [6.  3.  4.8 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.9 3.1 5.4 2.1], 2 (virginica) predicted as expected.\n",
      "For [6.7 3.1 5.6 2.4], 2 (virginica) predicted as expected.\n",
      "For [6.9 3.1 5.1 2.3], 2 (virginica) predicted as expected.\n",
      "For [5.8 2.7 5.1 1.9], 2 (virginica) predicted as expected.\n",
      "For [6.8 3.2 5.9 2.3], 2 (virginica) predicted as expected.\n",
      "For [6.7 3.3 5.7 2.5], 2 (virginica) predicted as expected.\n",
      "For [6.7 3.  5.2 2.3], 2 (virginica) predicted as expected.\n",
      "For [6.3 2.5 5.  1.9], 2 (virginica) predicted as expected.\n",
      "For [6.5 3.  5.2 2. ], 2 (virginica) predicted as expected.\n",
      "For [6.2 3.4 5.4 2.3], 2 (virginica) predicted as expected.\n",
      "For [5.9 3.  5.1 1.8], 2 (virginica) predicted as expected.\n",
      "\n",
      "Sorry I failed 4 times\n"
     ]
    }
   ],
   "source": [
    "es = []\n",
    "nb = 0\n",
    "for i in range(len(iris_Y)):\n",
    "    es.append(est.gcap(iris_X[i]))\n",
    "    if(es[i] != iris_Y[i]):\n",
    "        nb += 1\n",
    "        print(\"For {}, {} ({}) predicted instead of {} ({}).\".format(iris_X[i],es[i],iris.target_names[es[i]],iris_Y[i],iris.target_names[iris_Y[i]]))\n",
    "    else:\n",
    "        print(\"For {}, {} ({}) predicted as expected.\".format(iris_X[i],es[i],iris.target_names[es[i]]))\n",
    "print(\"\\nSorry I failed {} times\".format(nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probable risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk = 2.666666666666667 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Risk = {} %\".format(nb/len(iris_Y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating using $\\Lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### $\\widehat{\\omega}_k$ and  $\\widehat{\\mu}_k$ remain thesame as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimating $\\widehat{\\Lambda}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.259708  , 0.09122   , 0.16409333, 0.037704  ],\n",
       "        [0.09122   , 0.11356667, 0.05413333, 0.03275467],\n",
       "        [0.16409333, 0.05413333, 0.18146667, 0.04169067],\n",
       "        [0.037704  , 0.03275467, 0.04169067, 0.04117067]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.Lamda() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementing on iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For [5.1 3.5 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.9 3.  1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.7 3.2 1.3 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.6 3.1 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.6 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.4 3.9 1.7 0.4], 0 (setosa) predicted as expected.\n",
      "For [4.6 3.4 1.4 0.3], 0 (setosa) predicted as expected.\n",
      "For [5.  3.4 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.4 2.9 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.9 3.1 1.5 0.1], 0 (setosa) predicted as expected.\n",
      "For [5.4 3.7 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.8 3.4 1.6 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.8 3.  1.4 0.1], 0 (setosa) predicted as expected.\n",
      "For [4.3 3.  1.1 0.1], 0 (setosa) predicted as expected.\n",
      "For [5.8 4.  1.2 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.7 4.4 1.5 0.4], 0 (setosa) predicted as expected.\n",
      "For [5.4 3.9 1.3 0.4], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.5 1.4 0.3], 0 (setosa) predicted as expected.\n",
      "For [5.7 3.8 1.7 0.3], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.8 1.5 0.3], 0 (setosa) predicted as expected.\n",
      "For [5.4 3.4 1.7 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.7 1.5 0.4], 0 (setosa) predicted as expected.\n",
      "For [4.6 3.6 1.  0.2], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.3 1.7 0.5], 0 (setosa) predicted as expected.\n",
      "For [4.8 3.4 1.9 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.  1.6 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.4 1.6 0.4], 0 (setosa) predicted as expected.\n",
      "For [5.2 3.5 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.2 3.4 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.7 3.2 1.6 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.8 3.1 1.6 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.4 3.4 1.5 0.4], 0 (setosa) predicted as expected.\n",
      "For [5.2 4.1 1.5 0.1], 0 (setosa) predicted as expected.\n",
      "For [5.5 4.2 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.9 3.1 1.5 0.1], 0 (setosa) predicted as expected.\n",
      "For [5.  3.2 1.2 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.5 3.5 1.3 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.9 3.1 1.5 0.1], 0 (setosa) predicted as expected.\n",
      "For [4.4 3.  1.3 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.4 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.5 1.3 0.3], 0 (setosa) predicted as expected.\n",
      "For [4.5 2.3 1.3 0.3], 0 (setosa) predicted as expected.\n",
      "For [4.4 3.2 1.3 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.5 1.6 0.6], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.8 1.9 0.4], 0 (setosa) predicted as expected.\n",
      "For [4.8 3.  1.4 0.3], 0 (setosa) predicted as expected.\n",
      "For [5.1 3.8 1.6 0.2], 0 (setosa) predicted as expected.\n",
      "For [4.6 3.2 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.3 3.7 1.5 0.2], 0 (setosa) predicted as expected.\n",
      "For [5.  3.3 1.4 0.2], 0 (setosa) predicted as expected.\n",
      "For [7.  3.2 4.7 1.4], 1 (versicolor) predicted as expected.\n",
      "For [6.4 3.2 4.5 1.5], 1 (versicolor) predicted as expected.\n",
      "For [6.9 3.1 4.9 1.5], 1 (versicolor) predicted as expected.\n",
      "For [5.5 2.3 4.  1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.5 2.8 4.6 1.5], 1 (versicolor) predicted as expected.\n",
      "For [5.7 2.8 4.5 1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.3 3.3 4.7 1.6], 1 (versicolor) predicted as expected.\n",
      "For [4.9 2.4 3.3 1. ], 1 (versicolor) predicted as expected.\n",
      "For [6.6 2.9 4.6 1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.2 2.7 3.9 1.4], 1 (versicolor) predicted as expected.\n",
      "For [5.  2.  3.5 1. ], 1 (versicolor) predicted as expected.\n",
      "For [5.9 3.  4.2 1.5], 1 (versicolor) predicted as expected.\n",
      "For [6.  2.2 4.  1. ], 1 (versicolor) predicted as expected.\n",
      "For [6.1 2.9 4.7 1.4], 1 (versicolor) predicted as expected.\n",
      "For [5.6 2.9 3.6 1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.7 3.1 4.4 1.4], 1 (versicolor) predicted as expected.\n",
      "For [5.6 3.  4.5 1.5], 1 (versicolor) predicted as expected.\n",
      "For [5.8 2.7 4.1 1. ], 1 (versicolor) predicted as expected.\n",
      "For [6.2 2.2 4.5 1.5], 1 (versicolor) predicted as expected.\n",
      "For [5.6 2.5 3.9 1.1], 1 (versicolor) predicted as expected.\n",
      "For [5.9 3.2 4.8 1.8], 2 (virginica) predicted instead of 1 (versicolor).\n",
      "For [6.1 2.8 4.  1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.3 2.5 4.9 1.5], 1 (versicolor) predicted as expected.\n",
      "For [6.1 2.8 4.7 1.2], 1 (versicolor) predicted as expected.\n",
      "For [6.4 2.9 4.3 1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.6 3.  4.4 1.4], 1 (versicolor) predicted as expected.\n",
      "For [6.8 2.8 4.8 1.4], 1 (versicolor) predicted as expected.\n",
      "For [6.7 3.  5.  1.7], 1 (versicolor) predicted as expected.\n",
      "For [6.  2.9 4.5 1.5], 1 (versicolor) predicted as expected.\n",
      "For [5.7 2.6 3.5 1. ], 1 (versicolor) predicted as expected.\n",
      "For [5.5 2.4 3.8 1.1], 1 (versicolor) predicted as expected.\n",
      "For [5.5 2.4 3.7 1. ], 1 (versicolor) predicted as expected.\n",
      "For [5.8 2.7 3.9 1.2], 1 (versicolor) predicted as expected.\n",
      "For [6.  2.7 5.1 1.6], 2 (virginica) predicted instead of 1 (versicolor).\n",
      "For [5.4 3.  4.5 1.5], 1 (versicolor) predicted as expected.\n",
      "For [6.  3.4 4.5 1.6], 1 (versicolor) predicted as expected.\n",
      "For [6.7 3.1 4.7 1.5], 1 (versicolor) predicted as expected.\n",
      "For [6.3 2.3 4.4 1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.6 3.  4.1 1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.5 2.5 4.  1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.5 2.6 4.4 1.2], 1 (versicolor) predicted as expected.\n",
      "For [6.1 3.  4.6 1.4], 1 (versicolor) predicted as expected.\n",
      "For [5.8 2.6 4.  1.2], 1 (versicolor) predicted as expected.\n",
      "For [5.  2.3 3.3 1. ], 1 (versicolor) predicted as expected.\n",
      "For [5.6 2.7 4.2 1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.7 3.  4.2 1.2], 1 (versicolor) predicted as expected.\n",
      "For [5.7 2.9 4.2 1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.2 2.9 4.3 1.3], 1 (versicolor) predicted as expected.\n",
      "For [5.1 2.5 3.  1.1], 1 (versicolor) predicted as expected.\n",
      "For [5.7 2.8 4.1 1.3], 1 (versicolor) predicted as expected.\n",
      "For [6.3 3.3 6.  2.5], 2 (virginica) predicted as expected.\n",
      "For [5.8 2.7 5.1 1.9], 2 (virginica) predicted as expected.\n",
      "For [7.1 3.  5.9 2.1], 2 (virginica) predicted as expected.\n",
      "For [6.3 2.9 5.6 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.5 3.  5.8 2.2], 2 (virginica) predicted as expected.\n",
      "For [7.6 3.  6.6 2.1], 2 (virginica) predicted as expected.\n",
      "For [4.9 2.5 4.5 1.7], 2 (virginica) predicted as expected.\n",
      "For [7.3 2.9 6.3 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.7 2.5 5.8 1.8], 2 (virginica) predicted as expected.\n",
      "For [7.2 3.6 6.1 2.5], 2 (virginica) predicted as expected.\n",
      "For [6.5 3.2 5.1 2. ], 2 (virginica) predicted as expected.\n",
      "For [6.4 2.7 5.3 1.9], 2 (virginica) predicted as expected.\n",
      "For [6.8 3.  5.5 2.1], 2 (virginica) predicted as expected.\n",
      "For [5.7 2.5 5.  2. ], 2 (virginica) predicted as expected.\n",
      "For [5.8 2.8 5.1 2.4], 2 (virginica) predicted as expected.\n",
      "For [6.4 3.2 5.3 2.3], 2 (virginica) predicted as expected.\n",
      "For [6.5 3.  5.5 1.8], 2 (virginica) predicted as expected.\n",
      "For [7.7 3.8 6.7 2.2], 2 (virginica) predicted as expected.\n",
      "For [7.7 2.6 6.9 2.3], 2 (virginica) predicted as expected.\n",
      "For [6.  2.2 5.  1.5], 2 (virginica) predicted as expected.\n",
      "For [6.9 3.2 5.7 2.3], 2 (virginica) predicted as expected.\n",
      "For [5.6 2.8 4.9 2. ], 2 (virginica) predicted as expected.\n",
      "For [7.7 2.8 6.7 2. ], 2 (virginica) predicted as expected.\n",
      "For [6.3 2.7 4.9 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.7 3.3 5.7 2.1], 2 (virginica) predicted as expected.\n",
      "For [7.2 3.2 6.  1.8], 2 (virginica) predicted as expected.\n",
      "For [6.2 2.8 4.8 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.1 3.  4.9 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.4 2.8 5.6 2.1], 2 (virginica) predicted as expected.\n",
      "For [7.2 3.  5.8 1.6], 2 (virginica) predicted as expected.\n",
      "For [7.4 2.8 6.1 1.9], 2 (virginica) predicted as expected.\n",
      "For [7.9 3.8 6.4 2. ], 2 (virginica) predicted as expected.\n",
      "For [6.4 2.8 5.6 2.2], 2 (virginica) predicted as expected.\n",
      "For [6.3 2.8 5.1 1.5], 1 (versicolor) predicted instead of 2 (virginica).\n",
      "For [6.1 2.6 5.6 1.4], 2 (virginica) predicted as expected.\n",
      "For [7.7 3.  6.1 2.3], 2 (virginica) predicted as expected.\n",
      "For [6.3 3.4 5.6 2.4], 2 (virginica) predicted as expected.\n",
      "For [6.4 3.1 5.5 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.  3.  4.8 1.8], 2 (virginica) predicted as expected.\n",
      "For [6.9 3.1 5.4 2.1], 2 (virginica) predicted as expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For [6.7 3.1 5.6 2.4], 2 (virginica) predicted as expected.\n",
      "For [6.9 3.1 5.1 2.3], 2 (virginica) predicted as expected.\n",
      "For [5.8 2.7 5.1 1.9], 2 (virginica) predicted as expected.\n",
      "For [6.8 3.2 5.9 2.3], 2 (virginica) predicted as expected.\n",
      "For [6.7 3.3 5.7 2.5], 2 (virginica) predicted as expected.\n",
      "For [6.7 3.  5.2 2.3], 2 (virginica) predicted as expected.\n",
      "For [6.3 2.5 5.  1.9], 2 (virginica) predicted as expected.\n",
      "For [6.5 3.  5.2 2. ], 2 (virginica) predicted as expected.\n",
      "For [6.2 3.4 5.4 2.3], 2 (virginica) predicted as expected.\n",
      "For [5.9 3.  5.1 1.8], 2 (virginica) predicted as expected.\n",
      "\n",
      "Sorry I failed 3 times\n"
     ]
    }
   ],
   "source": [
    "es = []\n",
    "nb = 0\n",
    "for i in range(len(iris_Y)):\n",
    "    es.append(est.gcapLamda(iris_X[i]))\n",
    "    if(es[i] != iris_Y[i]):\n",
    "        nb += 1\n",
    "        print(\"For {}, {} ({}) predicted instead of {} ({}).\".format(iris_X[i],es[i],iris.target_names[es[i]],iris_Y[i],iris.target_names[iris_Y[i]]))\n",
    "    else:\n",
    "        print(\"For {}, {} ({}) predicted as expected.\".format(iris_X[i],es[i],iris.target_names[es[i]]))\n",
    "print(\"\\nSorry I failed {} times\".format(nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probable risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk = 2.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Risk = {} %\".format(nb/len(iris_Y)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
